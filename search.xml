<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Http 407 问题排查]]></title>
    <url>%2Fhttp-407-fix.html</url>
    <content type="text"><![CDATA[问题最近接一个新的代理平台出现了大量 Http 请求 407 的错误，主要是 HttpClient 的“延迟认证”导致的，排查原因记录下 basic 认证实现简单，但如果是 http 请求的话，信息会泄露，存在安全风险 https://juejin.im/entry/5ac175baf265da239e4e3999 认证流程client -> server：未携带认证信息server -> client：返回407client -> server：携带认证信息server -> client：返回200 注意这两步在代码层面是无感知的，只会收到最后的200。如果这个tcp连接已经建立，下次请求就会直接携带认证信息 看看 httpClient 的 debug 日志 1234567891011121314151617181920212223242526272829303132333435363738// 请求报文10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "GET Http://www.baidu.com/ HTTP/1.1[\r][\n]"10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "Host: www.baidu.com[\r][\n]"10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "Proxy-Connection: Keep-Alive[\r][\n]"10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "User-Agent: Apache-HttpClient/4.5.6 (Java/1.8.0_45)[\r][\n]"10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "Accept-Encoding: gzip,deflate[\r][\n]"10:19:46.002 [main] DEBUG org.apache.http.wire - http-outgoing-0 >> "[\r][\n]"// 返回报文10:19:46.034 [main] DEBUG org.apache.http.wire - http-outgoing-0 <]]></content>
      <categories>
        <category>异常排查</category>
      </categories>
      <tags>
        <tag>Http</tag>
        <tag>HttpClient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock 实现原理]]></title>
    <url>%2FReentrantLock.html</url>
    <content type="text"><![CDATA[Lock 简介Lock 是 JDK1.5 之后提供的接口，它提供了和 synchronized 类似的同步功能，比 synchronized 更为灵活，能弥补 synchronized 在一些业务场景中的短板。 Lock 的实现ReentrantLock可重入，排他，公平/非公平 ReentrantReadWriteLock共享&排他，可重入 StampedLock共享锁 CountdownLatch共享锁 AQS在 Lock 中，用到了一个同步队列 AQS，全称 AbstractQueuedSynchronizer，它是一个同步工具也是 Lock 用来实现线程同步的核心组件。 结构内部维护一个 FIFO 的双向链表，链表中的每个节点 Node 都记录了一个线程。当线程获取锁失败时，封装成 Node 加入到 AQS 队列中。当获取锁的线程释放锁时，会从队列中唤醒一个阻塞的线程。 Node 的 state 状态值在不同的实现类中表示不同的意思， 竞争锁节点的操作竞争成功假如第二个节点获取到了锁，head指向获取锁的节点，并断开与 next 的连接（前置节点 next 指向 null） 获取到锁的线程（头结点），会重新设置 head 指针，不存在竞争，普通操作即可。 竞争失败 只有 CAS 操作成功了，再去设置尾节点的 prev，此时不存在竞争，普通操作即可。 ReentrantLock#lock 的源码分析lock 操作时序图 NonfairSync#lock非公平锁和公平锁的区别是，非公平锁会先尝试修改 state 状态为1，修改成功表示获取锁成功，修改失败，会走 AQS 的 acquire 操作。 AQS#acquire会想尝试获取锁 tryAcquire，获取失败会将当前线程封装成 Node 节点添加到 AQS 队尾 addWaiter，并自旋尝试获取锁 acquireQueued。 NonfairSync#tryAcquire尝试获取锁，成功返回 true，不成功返回 false 无锁：尝试获取锁。有锁：判断是否是当前线程获取了锁 AQS#addWaiter如果 tryAcquire 方法获取锁失败后，会调用 addWaiter 将当前线程封装成 Node 添加到队尾。 如果队列不为空，尝试一次 CAS 添加对队尾。如果不成功，就调用 enq 方法自旋 CAS 添加到队列尾部 流程总结 tryAcquire -> addWaiter AQS#acquireQueued如果前置节点是头结点，就尝试获取锁。否则将前置节点 waitStatus 改为 SIGNAL，然后将当前线程挂起 ReentrantLock#unlock 源码分析释放锁，会唤醒后续的节点，唤醒的节点会在 acquireQueued 方法中继续运行（哪里跌倒，哪里爬起） AQS 疑难解惑enq 方法返回前置节点enq 方法，自旋将 node 添加到队列尾部，返回的是 node 的前置节点 AQS 需要一个虚拟的 head 节点线程挂起，需要将前置节点 ws 改为 SIGNAL 状态，这样才能保证自己被唤醒。虚拟的 head 节点就是为了处理这样的边界情况，保证第一个包含了线程的节点能够被唤醒。 AQS 通过判断前置节点 waitStatus 来唤醒节点线程，为什么？保证状态一致性，防止重复唤醒 参考https://www.cnblogs.com/stateis0/p/9062045.html https://www.cnblogs.com/dennyzhangdd/p/7218510.html#_label0]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[disrupt 实现原理]]></title>
    <url>%2Fdisrupt.html</url>
    <content type="text"><![CDATA[一、Disruptor 简介线程间通讯框架，实现多线程共享数据。是一个高性能无锁队列，由英国外汇交易公司 LMAX 开发。 性能测试：https://github.com/LMAX-Exchange/disruptor/wiki/Performance-Results 二、Disruptor 为什么这么快2.1 无锁操作生产数据消费数据都是通过申请序列，申请成功后才可以继续操作。而申请序列的操作时通过 CAS + LockSupport 完成的。 2.2 消除伪共享通过填充数据方式来实现消除伪共享 2.2.1 什么是伪共享cpu 三级缓存架构如下 thread1 和 thread2 读取数据会覆盖 cpu cache line 2.2.2 通过数据填充消除伪共享通过填充数据，使数据长度恰好等于一个缓存行长度（64 字节 or 128 字节），这样数据占据整个缓存行，就不会被别的数据覆盖。 Disruptor 中的 Sequence 序列号对象，通过先后数据填充，变为 128 个字节，实现伪共享消除的。 12345678910111213141516171819202122class LhsPadding{ protected long p1, p2, p3, p4, p5, p6, p7;}class Value extends LhsPadding{ protected volatile long value;}class RhsPadding extends Value{ protected long p9, p10, p11, p12, p13, p14, p15;}public class Sequence extends RhsPadding{ static final long INITIAL_VALUE = -1L; private static final Unsafe UNSAFE; private static final long VALUE_OFFSET;} 通过前置p1~p7，后置p9~p15填充缓存行，防止缓冲行共享。一般的处理器架构缓存行是64字节，但是有个处理器架构是128字节，所以采用前后填充，能够实现在所有处理器上消除伪共享。 2.3 环形 buffer内部采用数组存储数据，充分利用内存局部性原理。 只使用一个指针来表示可用数据，没有头尾指针。消除头尾指针竞争。各个生产者消费者只需要申请自己的序列号，就可以进行操作了。不存在竞争同一资源。 bufferSize 是 2 的 n 次幂，通过 sequence & (2^n -1) 来计算索引。 通过数据覆盖，不需要删除数据，无需 GC。 三、Disruptor 如何工作3.1 消费者端每个消费者都对应一个 ConsumerBarrier，消费者通过 ConsumerBarrier 与 Disruptor 交互。消费者通过 ConsumerBarrier 获取下一个可以消费的序列号，然后开始消费。比如消费者 A 当前消费的序列号是8，通过 ConsumerBarrier 获取下一个可消费的序列号是 12，那么消费者 A 可以批量消费序列号 9，10，11，12 的数据。 消费者消费数据步骤：1.获取序列号，2.消费数据 3.2 生产者端多个生产者对应一个 Sequencer，也就是说多个生产者共用一个序列号。 生产者生产数据步骤：1.申请序列号，2.填充数据，3.发布 生产者 A 和生产者 B 同时生产数据，如下图： 生产者 A 讯轮阻塞 等待消费者 A，如下图： 消费者 A 轮训非阻塞 等待生产者 B，如下图： 四、源码导读4.1 核心类https://github.com/LMAX-Exchange/disruptor/wiki/Introduction ringbuff上有指针，每个消费者都维护自己的一个指针，生产者共用一个指针。指针是由 Sequencer类来控制的假设buffsize=8，如果消费者在消费id7，生产者将生产id15（15-buffsize=7），是同一个位置，生产者阻塞，如果生产者在生产id7，消费者在消费id7，消费者阻塞 4.2 生产者端4.2.1 申请序号调用 Sequencer#get ，直接看多生产者如果申请序号的 123456789101112131415161718192021222324252627282930313233343536373839404142public long next(int n){ if (n < 1) { throw new IllegalArgumentException("n must be > 0"); } long current; long next; do { // 获取当前发布序号 current = cursor.get(); next = current + n; long wrapPoint = next - bufferSize; // gatingSequenceCache 这是 gatingSequence 的缓存，存入的是最小的消费者消费序列（有多个消费者） long cachedGatingSequence = gatingSequenceCache.get(); // 生产者要覆盖未被消费的数据（生产者超过消费者一圈了） if (wrapPoint > cachedGatingSequence || cachedGatingSequence > current) { // 获取最小的消费者序列 long gatingSequence = Util.getMinimumSequence(gatingSequences, current); if (wrapPoint > gatingSequence) { LockSupport.parkNanos(1); // TODO, should we spin based on the wait strategy? continue; } // 更新缓存 gatingSequenceCache.set(gatingSequence); } else if (cursor.compareAndSet(current, next)) { break; } } while (true); return next;} 4.2.2 写入数据12345 public E get(long sequence) { return (E)entries[(int)sequence & indexMask]; }// dosomething 4.2.3发布123456public void publish(final long sequence){ // 将待发布的序列设为可用，这样消费者就可以消费这个序列了 setAvailable(sequence); waitStrategy.signalAllWhenBlocking();} 4.3 消费者端Disruptor#start 启动，会在线程池里启动 EventProcessor，每个 EventHandler 对应一个 EventProcessor BatchEventProcessor 是 EventProcessor 的实现类，run方法里会轮训，是否有 event 可以被消费，如果可以就调用 EventHandler#onEvent 方法，触发消费者事件。 重点看 BatchEventProcessor#run 方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public void run(){ // 状态设为启动，是一个AtomicBoolean if (!running.compareAndSet(false, true)) { throw new IllegalStateException("Thread is already running"); } // 清除中断 sequenceBarrier.clearAlert(); // 判断一下消费者是否实现了LifecycleAware ,如果实现了这个接口，那么此时会发送一个启动通知 notifyStart(); T event = null; long nextSequence = sequence.get() + 1L; try { while (true) { try { // 获取最大可用的序号，表示在之前的都可以安全消费 final long availableSequence = sequenceBarrier.waitFor(nextSequence); while (nextSequence]]></content>
      <categories>
        <category>javaWeb</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>disruptor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[caffeine 缓存实现原理]]></title>
    <url>%2Fcaffeine.html</url>
    <content type="text"><![CDATA[一、背景我们知道 HashMap 可以作为进程内缓存，他不受外部系统影响，速度快。但是他不能像分布式缓存那样能够实时刷新，且本地内存有限，需要限定 HashMap 的容量范围，这就涉及到缓存淘汰问题。为了解决本地缓存的这些问题，Guava Cache 应运而生，他提供了异步刷新和 LRU 淘汰策略。Guava Cache 功能虽然强大，但是只是对 LRU 的一层封装，在复杂的业务场景下，LRU 淘汰策略显得力不从心。为此基于 W-TinyLFU(LFU+LRU算法的变种) 淘汰策略的进程内缓存 —— Caffeine Cache 诞生了。 Caffeine 的设计实现来自于大量优秀的研究，SpringBoot2 和 Spring5 已经默认支持 Caffeine Cache 代替原来的 Guava Cache，足以见得 Caffeine Cache 的地位。 本文将试着探究 Guava Cache 和 Caffeine Cache 的实现原理，重点讲解 Caffeine Cache 相比于 Guava Cache 有哪些优秀的设计和改动。本文研究的 caffeine 版本是 2.7.0，guava 版本是 27.1-jre。 二、缓存淘汰算法因为本地内存非常有限，我们的进程内缓存必须是有界的，需要进行数据淘汰，将无效的数据驱逐。一个好的淘汰算法，决定了其命中率高低。下面会简单介绍一些常见的淘汰算法，以便于后续的深入讲解。 2.1 LFULFU（Least Frequently Used，最近最不常用）根据数据的访问频率，淘汰掉最近访问频率最低的数据，其核心思想是“如果数据过去被访问多次，那么将来被访问的频率也更高”。 需要维护每个数据项的访问频率信息，每次访问都需要更新，这个开销是非常大的。 LFU 能够很好地应对偶发性、周期性的批量操作，不会造成缓存污染。但是对于突发性的热点事件，比如外卖中午时候访问量突增、微博爆出某明星糗事就是一个突发性热点事件。当事件结束后，可能没有啥访问量了，但是由于其极高的访问频率，导致其在未来很长一段时间内都不会被淘汰掉。 2.2 LRULRU（Least recently used，最近最少使用）根据数据的访问记录，淘汰掉最近最少使用的数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”（时间局部性原理）。 需要用 queue 来保存访问记录，可以用 LinkedHashMap 来简单实现一个基于 LRU 算法的缓存。 当存在热点数据时，LRU的效率很好。但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。 2.3 TinyLFUTinyLFU 顾名思义，轻量级LFU，相比于 LFU 算法用更小的内存空间来记录访问频率。 TinyLFU 维护了近期访问记录的频率信息，不同于传统的 LFU 维护整个生命周期的访问记录，所以他可以很好地应对突发性的热点事件（超过一定时间，这些记录不再被维护）。这些访问记录会作为一个过滤器，当新加入的记录（New Item）访问频率高于将被淘汰的缓存记录（Cache Victim）时才会被替换。流程如下： 尽管维护的是近期的访问记录，但仍然是非常昂贵的，TinyLFU 通过 Count-Min Sketch 算法来记录频率信息，它占用空间小且误报率低，关于 Count-Min Sketch 算法可以参考论文：pproximating Data with the Count-Min Data Structure 2.4 W-TinyLFUW-TinyLFU 算法相比于 LRU 等算法，具有更高的命中率。下图是一个运行了 ERP 应用的数据库服务中各种算法的命中率，实验数据来源于 ARC 算法作者，更多场景的性能测试参见：官网 （图片来源于：https://github.com/ben-manes/caffeine/wiki/Efficiency） W-TinyLFU 算法是对 TinyLFU算法的优化，能够很好地解决一些稀疏的突发访问元素。在一些数目很少但突发访问量很大的场景下，TinyLFU将无法保存这类元素，因为它们无法在短时间内积累到足够高的频率，从而被过滤器过滤掉。W-TinyLFU 将新记录暂时放入 Window Cache 里面，只有通过 TinLFU 考察才能进入 Main Cache。大致流程如下图： 三、缓存事务为了实现缓存的过期策略，我们需要在访问数据的时候记录一系列信息，我们将该操作定义为缓存事务。 对于一个实现了写后过期的缓存，需要在其 put 操作时，记录 entry 的写时间，后续通过这个 entry 写时间来判断其是否过期。对于一个实现了读后过期的缓存，需要在其 get 操作时记录 entry 的最后访问时间，后续通过 entry 的最后访问时间来判断其是否过期。对于一个实现了 LFU 淘汰策略的缓存，需要在每次 get 操作时记录 entry 的访问次数，后续通过 entry 的访问次数来判断其是否淘汰。为了便于后续的表述，对于这种为实现缓存的过期淘汰策略而做的一系列额外操作，我们将其定义为缓存事务。 四、guava 缓存guava 缓存提供了基于容量、时间、引用的过期策略。基于容量的实现是采用 LRU 算法。基于引用的实现是借助于 JVM GC，因为缓存的key被封装在WeakReference引用内，缓存的Value被封装在WeakReference或SoftReference引用内。 为了减少读写缓存的并发问题，参考了 JDK1.7 版本的 ConcurrentHashMap，实现了分段锁机制来减少锁粒度。然而分段锁机制不是非常好的方案，JDK1.8 已经取消了 ConcurrentHashMap 的分段锁，采用的 CAS + synchronized，他只锁住数组的单个元素。关于 ConcurrentHashMap 在 JDK1.8 中的改进，这里不再展开。 采用 LRU 过期策略，每个 Segment 维护三个 queue，writeQueue 、 accessQueue和recencyQueue。其中 recencyQueue 是记录 get 操作命中的，accessQueue 是记录 get 操作未命中的。recencyQueue 是无锁操作，需要保证线程安全。 值得注意的是，在高并发下，queue的竞争是比较激烈，guava 是在 每个 put/get 操作时记录到对应的 queue，这样增加了用户端的耗时。 过期策略是在访问数据的时候，判断是否过期。这样做好处是不需要后台线程定期扫描，但增加了耗时和内存损耗（本该过期的数据没有及时过期）。 4.1 Guava 缓存的执行流程guava 的事务操作是在读取缓存时一起执行的，读取缓存操作流程如下： 事务处理在读取缓存时同步进行，这样的好处是不需要后台线程定期扫描处理事务，保证数据的实时性，但会增加一定的耗时。 4.2 Guava 缓存中的事务处理 采用 LRU 过期策略，每个 Segment 维护三个 queue，writeQueue 、 accessQueue和recencyQueue。用来实现不同情况的 LRU 淘汰策略。其中 recencyQueue 是记录 get 命中操作的，这是个多线程操作，Guava 通过线程安全的 recencyQueue 来记录，然后通过单线程批量 recencyQueue 将访问记录添加到非线程安全的 accessQueue，可以看出 recencyQueue 起到缓冲的作用。 正因为 recencyQueue 是线程安全的，在 get 操作时又增加了并发竞争耗时（将 Entry 添加到 recencyQueue）。 五、caffeine 缓存相比于 Guava 缓存，采用了更加先进的过期策略 W-TinyLFU，通过 RingBuffer 缓存事务，并用后台进程批量处理事务。Caffeine 直接采用的是 ConcurrentHashMap，要知道 ConcurrentHashMap 在 JDK1.8 是有非常大的性能提升的。 简单讲，Caffeine 是对 ConcurrentHashMap 进行封装，采用缓冲和后台线程批量处理事务，Caffeine 官方称其并发性能近视等于 ConcurrentHashMap。 Caffeine 官方做了性能测试，其中 6 线程读 2 线程写吞吐量如下图： （图片来源于：https://github.com/ben-manes/caffeine/wiki/Benchmarks） 可以看到 Caffeine 缓存吞吐量远超 Guava 缓存，其余场景性能测试详见：官网 5.1 基于 W-TinyLFU前面已经提到了 W-TinyLFU 算法，Caffeine 采用 W-TinyLFU 算法来实现其淘汰策略。Caffeine 内部维护了三个 queue，分别为： access order queue，实现读后过期 write order queue，实现写后过期 Hierarchical TimerWheel，实现定时过期 在大多数情况下，读操作远比写操作多，因此 Caffeine 为了提高读并发能力，采用分段策略，将 access order queue 分为三种，分别是 WindowDeque、ProbationDeque、ProtectedDeque。这三者关系如下： 结合 W-TinyLFU 算法，可以得出记录从产生到淘汰的整个流程： （图片来源于：http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html） 新的记录会进入第一个 LRU，这个在 Caffeine 里是 WindowDeque。之后通过过滤器过滤，过滤器通过访问频率来实现过滤，只有高于将要淘汰数据的使用频率才能进入缓存。这个频率信息维护就是前面提到的 Count-Min Sketch 算法来实现的，具体是 FrequencySketch 类。 5.1.1 过期策略Caffeine 采用统一的过期时间，这样可以实现 O(1) 复杂度往队列里添加和取出记录。对于写后过期，维护一个写入顺序队列，对于读后过期，维护一个读顺序队列。值得注意的是，这些操作都是单线程异步执行的。 5.2 执行流程与 Guava 最大的不同就是，Caffeine 在读取缓存操作时，将事务提交到缓存异步批量处理，大致处理流程如下： 5.3 缓存区5.3.1 readBuffer 采用RingBuffer，有损。为了进一步减少读并发，采用多个 RingBuffer（striped ring buffer 条带环形缓冲），通过线程 id 哈希到对应的RingBuffer。环形缓存的一个显著特点是不需要进行 GC，直接通过覆盖过期数据。 当一个 RingBuffer 容量满载后，会触发异步的执行操作，而后续的对该 ring buffer 的写入会被丢弃，直到这个 ring buffer 可被使用，因此 readBuffer 记录读缓存事务是有损的。因为读记录是为了优化驱策策略，允许他有损。 5.3.2 writeBuffer采用传统的有界队列 ArrayQueue，无损 5.4 状态机缓冲区和细粒度的写带来了单个数据项的操作乱序的竞态条件。插入、读取、更新、删除都可能被各种顺序的重放，如果这个策略控制的不合适，则可能引起悬垂索引。解决方案是通过状态机来定义单个数据项的生命周期。这类似于 AQS 中的原子类型变量 state。 5.5 事务处理 5.6 caffeine get 操作流程图 六、参考http://highscalability.com/blog/2016/1/25/design-of-a-modern-cache.html https://github.com/ben-manes/caffeine TinyLFU: A Highly Eﬃcient Cache Admission Policy Approximating Data with the Count-Min Data Structure https://segmentfault.com/a/1190000016091569 https://chuansongme.com/n/2254051]]></content>
      <categories>
        <category>javaWeb</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>caffeine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[protobuf 安装使用]]></title>
    <url>%2Fprotobuf-use.html</url>
    <content type="text"><![CDATA[安装 官网下载 https://github.com/protocolbuffers/protobuf/releases 解压，cd 到目录下 ./configure make make check sudo make install which protoc protoc –version 使用编写proto文件（idl文件）一个名为 Person.proto文件如下：1234567syntax="proto3"; option java_package = "org.serialization.protobuf.quickstart"; option java_outer_classname = "PersonProtobuf"; message Person { int32 age = 1; string name = 2;} 编译使用 protoc 编译器，将 proto 文件编译成 java 文件 1protoc --java_out=./ Person.proto 序列化调用引入 maven 依赖 12345 com.google.protobuf protobuf-java 3.1.0]]></content>
      <categories>
        <category>javaWeb</category>
      </categories>
      <tags>
        <tag>protobuf</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2Fsingleton.html</url>
    <content type="text"><![CDATA[饿汉式单例类加载立即初始化，绝对线程安全，不存在访问安全问题。Spring IOC 容器 ApplicationContext 就是一个饿汉式单例。 优点：没有任何加锁，执行效率高，用户体验好 缺点：类加载就初始化，浪费空间 简单实例： 12345678910public class HungrySingleton { /** 也可以放在静态代码块中 */ private static final HungrySingleton HUNGRY_SINGLETON = new HungrySingleton(); private HungrySingleton() {} public static HungrySingleton getInstance() { return HUNGRY_SINGLETON; }} 懒汉式单例需要时才加载 通过 double-check 实现：1234567891011121314151617181920public class LazyDoubleCheckSingleton { // 需要用 volatile 修饰保证可见性和重排序 private static volatile LazyDoubleCheckSingleton lazy; private LazyDoubleCheckSingleton() {} public static LazyDoubleCheckSingleton getInstance() { if (lazy == null) { synchronized (LazyDoubleCheckSingleton.class) { if (lazy == null) { // 1.分配内存给对象 // 2.初始化对象 // 3.lazy 指向该对象 lazy = new LazyDoubleCheckSingleton(); } } } return lazy; }} 通过静态内部类实现：double-check 方法需要加锁，对程序性能有一定影响，用静态内部类实现更好 123456789101112131415161718192021222324/** * @author zhouxinghang * @date 2019-05-16 * 外部类初次加载，会初始化静态变量、静态代码块、静态方法，但不会加载内部类和静态内部类。 * 实例化外部类，调用外部类的静态方法、静态变量，则外部类必须先进行加载，但只加载一次。 * 直接调用静态内部类时，外部类不会加载。 */public class LazySingleton { private LazySingleton(){} /** * final 保证方法不被重写 * @return */ public static final LazySingleton getInstance() { return LazySingletonHolder.LAZY_SINGLETON; } private static class LazySingletonHolder { private static final LazySingleton LAZY_SINGLETON = new LazySingleton(); }} 单例模式的破坏反射破坏单例模式尽管构造方法加了 private 修饰，但是可以通过反射调用构造方法，因此对构造方法加以限制，重复创建直接抛出异常。 以上述 LazySingleton 为例： 123456private LazySingleton(){ // 如果通过反射来创建实例，就抛出异常 if (LazySingletonHolder.LAZY_SINGLETON != null) { throw new RuntimeException("不允许创建多个不同实例"); }} 序列化破坏单例模式在序列化操作时，反序列化后的对象会重新分配内存空间，即重新创建，如果目标是单例对象，就会破坏单例模式。 对此，我们只需要增加 readResolve() 方法即可。以上述 LazySingleton 为例，修改如下： 123456789101112131415161718192021222324252627282930public class LazySingleton implements Serializable { private LazySingleton(){ // 如果通过反射来创建实例，就抛出异常 if (LazySingletonHolder.LAZY_SINGLETON != null) { throw new RuntimeException("不允许创建多个不同实例"); } } /** * final 保证方法不被重写 * @return */ public static final LazySingleton getInstance() { return LazySingletonHolder.LAZY_SINGLETON; } /** * 保证反序列化还是原对象 * @return */ private Object readResolve() { return LazySingletonHolder.LAZY_SINGLETON; } private static class LazySingletonHolder { private static final LazySingleton LAZY_SINGLETON = new LazySingleton(); }} 至于为什么，需要看 JDK 序列化源码。ObjectInputStream 类的 readObject() -> readObject0() -> readOrdinaryObject() -> invokeReadResolve()。invokeReadResolve 代码如下： 而 readResolveMethod 是在在私有方法 ObjectStreamClass() 中赋值的，代码如下： 可见的，如果被序列化的类定义了 readResolve() 方法，就会调用该方法实现反序列化。 增加 readResolve() 方法可以防止单例模式被破坏，但是在 readOrdinaryObject() 方法中还是会创建一个新对象的，只不过返回的是readResolve() 方法返回值。具体代码如下： 注册式单例可以避免这个问题 注册式单例注册式单例又称为登记式单例，就是将每一个实例都登记到某一个地方，使用唯一的标 识获取实例。注册式单例有两种写法：一种为容器缓存，一种为枚举登记。枚举单例也是《Effective Java》书中推荐的一种单例实现写法 枚举单例1234567891011121314151617public enum EnumSingleton { INSTANCE; private Object date; public Object getDate() { return date; } public void setDate(Object date) { this.date = date; } public static EnumSingleton getInstance() { return INSTANCE; }} 通过反编译发现枚举类是通过静态代码块实现的饿汉式单例模式，反编译代码如下： 1234567static{ INSTANCE = new EnumSingleton("INSTANCE", 0); $VALUES = (new EnumSingleton[] { INSTANCE });} 枚举缓存既不会被序列化破坏，也不会被反射破坏。 对于序列化，在 ObjectInputStream 类中 readEnum() 方法里，发现枚举类型是通过类名和 Class 对象类找到唯一的枚举对象，代码如下： 对于反射，Constructor 类中的 newInstance() 方法对于枚举类，直接抛出异常： 容器缓存单例可以看看 Spring 容器式单例实现：]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 实现 NTFS 格式硬盘读写]]></title>
    <url>%2Fmac-NTFS.html</url>
    <content type="text"><![CDATA[理论Mac本身是支持NTFS写入的，只是NTFS是微软开发，由于版权和一些技术细节原因，苹果不愿公开说自己支持NTFS写入，也是有自己以后可能不支持NTFS写入的考量 操作流程 挂载上你的NTFS硬盘，查看硬盘名称 编辑/etc/fstab文件，使其支持NTFS写入 将/Volumes中的NTFS磁盘快捷方式到Finder 详细流程 插上硬盘后，查看你的硬盘名称，这里假设名称是AngleDisk 打开Applications的Terminal, 你也可以直接spotlight输入terminal打开 在终端输入sudo nano /etc/fstab 敲击回车 现在你看到了一个编辑界面，输入LABEL=AngleDisk none ntfs rw,auto,nobrowse后，敲击回车，再Ctrl+X，再敲击Y，再敲击回车 此时，退出你的移动硬盘，再重新插入，你会发现磁盘没有显示在桌面或是Finder之前出现的地方，别慌 打开Finder，Command+Shift+G，输入框中输入/Volumes，回车，你就可以看到你的磁盘啦！是可以读写的哟，Enjoy 方便起见，你可以直接把磁盘拖到Finder侧边栏中，这样下次使用就不用进入到/Volumes目录打开le 参考https://www.zhihu.com/question/19571334]]></content>
      <categories>
        <category>计算机操作</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>ntfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker基础]]></title>
    <url>%2Fdocker-base.html</url>
    <content type="text"><![CDATA[Docker 简介什么是 DockerDocker 是 dotCloud 公司创立，go 语言编写，基于 Ubuntu 开发。基于 Linux 内核的 cgroup，namespace，以及 AUFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。隔离的进程独立于宿主和隔离的其他进程，也其曾为容器。 传统的虚拟机技术是虚拟一套硬件出来，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。而容器是直接运行在宿主机的内核，没有进行硬件虚拟。因此容器比传统虚拟机更为轻便。 为什么要使用 Docker更高效利用系统资源不需要硬件虚拟化，不需要运行完整 OS 更快速的启动时间直接运行于宿主内核，做到秒级、甚至毫秒级启动 一致的运行环境提供了除内核外完整的运行时环境 高效部署扩容对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 Docker 架构docker 采用 C/S 架构，Client 通过结构与 Server 进程通信实现容器的构建，运行和发布 Client 和 Server 可以运行在同一台机器，也可以通过跨主机实现远程通信 组件 描述 镜像（Images） 用于创建 Docker 容器的模板 容器（Container） 独立运行的一个或一组应用 客户端（Client） 通过命令行或其他工具调用 Docker API 主机（Host） 一个宿主机用于执行 Docker 守护进程和容器 注册服务器（Registry） 用于保存镜像，类似于 git 厂库。Docker Hub(https://hub.docker.com) 提供了庞大的镜像集合供使用。 镜像 image操作系统分为内核和用户控件，对于 Linux 而言，内核启动后，会挂载 root 文件系统为其用户空间提供支持。而 Docker Image，就相当于一个 root 文件系统。 Docker Image 是一个特殊的文件系统，包好了提供容器运行所需的程序、库、资源、配置等文件外，还包括一些配置参数信息（如匿名卷、环境变量、用户等）。镜像不包含任何动态数据，其内容在构建后不会改变。 分层存储Docker Image 不是 ISO 那样的打包文件，它采用 Union FS 技术，将其设计为分层存储的架构。后一层依赖于前一层，如果需要 update 只需要创建一个新的层。这有点类似于 git 版本管理，每一层就是一个 git commit。 容器 container镜像和容器就像面向对象程序中的类和实例对象。镜像是静态定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 容器 Container 实质是进程，与宿主进程不同，容器进程运行于属于自己独立的 namespace。因此容器拥有自己独立的 root 文件系统、网络配置、进程空间甚至自己的用户 ID 空间。 每个容器运行时，以镜像为基础层，在其上创建一个容器的存储层，为容器运行时读写而准备的存储层为容器存储层。容器存储层的生命周期和容器一致。容器存储层的数据也会随着容器的删除而删除。 按照 Docker 最佳实践要求，容器不应该像其容器存储层写入任务数据，容器存储层要保持无状态化。所有文件的写入都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发起读写，其性能和稳定性更高。 使用数据卷，容器删除或重新运行，数据不会丢失。 namespace命名空间是 Linux kernel 的功能，实现一个进程集合只能访问一个资源集合，实现资源和进程的分区，保证其相互独立。 命名空间是实现 Linux container 的基础。 仓库 repositoryDocker Repository 用于保存镜像，可以理解为代码控制中的代码仓库。Docker 仓库也分为公有和私有，公有是 Docker Hub 注册服务器 Registry集中存储分发镜像的服务，一个 Docker Registry 包含多个仓库 Repository，每个仓库包含多个标签 Tag，每个 标签对应一个镜像 Docker 实现原理命名空间 namespace命名空间是 Linux 提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法。 控制组 cgroups命名空间无法提供物理资源的隔离，比如 CPU 和内存，Linux 的控制组能够为一组进程分配资源（CPU, memory, disk I/O, network, etc.） UnionFSUnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。 Docker 基本命令docker version12345678910111213141516171819$ docker versionClient: Docker Engine - Community Version: 18.09.2 API version: 1.39 Go version: go1.10.8 Git commit: 6247962 Built: Sun Feb 10 04:12:39 2019 OS/Arch: darwin/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 18.09.2 API version: 1.39 (minimum version 1.12) Go version: go1.10.6 Git commit: 6247962 Built: Sun Feb 10 04:13:06 2019 OS/Arch: linux/amd64 Experimental: false docker info123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 18.09.2Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslogSwarm: inactiveRuntimes: runcDefault Runtime: runcInit Binary: docker-initcontainerd version: 9754871865f7fe2f4e74d43e2fc7ccd237edcbcerunc version: 09c8266bf2fcf9519a651b04ae54c967b9ab86ecinit version: fec3683Security Options: seccomp Profile: defaultKernel Version: 4.9.125-linuxkitOperating System: Docker for MacOSType: linuxArchitecture: x86_64CPUs: 4Total Memory: 1.952GiBName: linuxkit-025000000001ID: TCUF:2IMR:QS25:QSA3:XWGV:NL6K:B5OF:B6PQ:6I2L:LJQY:XYOS:BC4FDocker Root Dir: /var/lib/dockerDebug Mode (client): falseDebug Mode (server): true File Descriptors: 24 Goroutines: 50 System Time: 2019-04-10T02:47:02.917656675Z EventsListeners: 2HTTP Proxy: gateway.docker.internal:3128HTTPS Proxy: gateway.docker.internal:3129Registry: https://index.docker.io/v1/Labels:Experimental: falseInsecure Registries: 127.0.0.0/8Live Restore Enabled: falseProduct License: Community Engine docker search搜索镜像 123456789$ docker search ubuntu12.10NAME DESCRIPTION STARS OFFICIAL AUTOMATEDchug/ubuntu12.10x64 Ubuntu Quantal Quetzal 12.10 64bit base ima… 0 chug/ubuntu12.10x32 Ubuntu Quantal Quetzal 12.10 32bit base ima… 0 yuanzai/ubuntu12.10x64 0 mirolin/ubuntu12.10_redis 0 mirolin/ubuntu12.10 0 marcgibbons/ubuntu12.10 0 khovi/ubuntu12.10 0 docker pull下载镜像 123456789$ docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu898c46f3b1a1: Pull complete 63366dfa0a50: Pull complete 041d4cd74a92: Pull complete 6e1bee0f8701: Pull complete Digest: sha256:017eef0b616011647b269b5c65826e2e2ebddbe5d1f8c1e56b3599fb14fabec8Status: Downloaded newer image for ubuntu:latest docker images123456789$ docker pull ubuntuUsing default tag: latestlatest: Pulling from library/ubuntu898c46f3b1a1: Pull complete 63366dfa0a50: Pull complete 041d4cd74a92: Pull complete 6e1bee0f8701: Pull complete Digest: sha256:017eef0b616011647b269b5c65826e2e2ebddbe5d1f8c1e56b3599fb14fabec8Status: Downloaded newer image for ubuntu:latest docker runrun 使用镜像创建容器12$ docker run ubuntu /bin/echo hello worldhello world run 创建容器，并交互式的运行 -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标准输入保持打开 12345$ docker run -i -t ubuntu /bin/bashroot@5df6791cfcf7:/# root@5df6791cfcf7:/# lsbin dev home lib64 mnt proc run srv tmp varboot etc lib media opt root sbin sys usr run -d 守护态运行123# zhouxinghang @ zhouxinghangdeMacBook-Pro in ~/Documents/myworkspace [11:31:36] $ docker run -d ubuntu /bin/bash -c "while true;do echo hello world;sleep 1;done"95d8965f07977d237471a23fe128edf111f5c54cda85c9e3f4877c06dd60b12e docker logs 容器id 查看容器运行 12345678910111213141516171819# zhouxinghang @ zhouxinghangdeMacBook-Pro in ~/Documents/myworkspace [11:34:40] $ docker logs 95d8965f07977d237471a23fe128edf111f5c54cda85c9e3f4877c06dd60b12ehello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello worldhello world docker run 创建容器，执行步骤 检查本地是否存在指定镜像，若不存在就去仓库下载 利用镜像创建容器 分配文件系统，并在只读的镜像层外挂载一层读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完成，终止容器 docker ps 查看容器-a 包括退出的历史容器 123456$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES95d8965f0797 ubuntu "/bin/bash -c 'while…" 6 minutes ago Exited (137) 10 seconds ago elegant_montalcini5cd7025b91b9 ubuntu "/bin/bash" 12 minutes ago Exited (130) About a minute ago stoic_yonath5df6791cfcf7 ubuntu "/bin/bash" 40 minutes ago Exited (127) 15 minutes ago nifty_kirchc48f8cdf8076 ubuntu "/bin/echo hello wor…" 41 minutes ago Exited (0) 41 minutes ago elastic_robinson docker attach 容器id 连接容器当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 12$ docker attach 5cd7025b91b9root@5cd7025b91b9:/var/log# 其它命令 commit 将容器的状态保存为镜像 diff 查看容器内容变化 cp 拷贝文件 inspect 收集容器和镜像的底层信息 kill 停止容器主进程 参考https://en.wikipedia.org/wiki/Linux_namespaces https://en.wikipedia.org/wiki/Cgroups https://en.wikipedia.org/wiki/Aufs http://dockone.io/article/2941 https://www.jianshu.com/p/4ab37ad30bd2]]></content>
      <categories>
        <category>javaWeb</category>
      </categories>
      <tags>
        <tag>javaWeb</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm参数]]></title>
    <url>%2Fjvm-options.html</url>
    <content type="text"><![CDATA[-X 与 -XX 的区别 Standard options :Options that begin with - are Standard options are expected to be accepted by all JVM implementations and are stable between releases (though they can be deprecated).Non-standard options :Options that begin with -X are non-standard (not guaranteed to be supported on all JVM implementations), and are subject to change without notice in subsequent releases of the Java SDK.Developer options :Options that begin with -XX are developer options and often have specific system requirements for correct operation and may require privileged access to system configuration parameters; they are not recommended for casual use. These options are also subject to change without notice. -XX 参数格式1）布尔类型 -XX:+option (true) -XX:-option (false) -XX:+DisableExplicitGC 2）数值类型 -XX:option=number 可以带单位 k,m,g(不区分大小写) -XX:SurvivorRatio=8 -XX:MetaspaceSize=256M 3）字符类型 -XX:option=String 通常用来设置文件名、路径等 -XX:HeapDumpPath=./java_pid.hprof 关于内存的参数设置 参数 说明 -Xms 初始堆大小，memory size -Xmx 堆最大值，max memory size，一般和 -Xms 设置同样的大小 -Xmn 新生代大小，new memory size -Xss 线程栈大小，stack size -XX:PermSize=256m 永生代初始大小，JDK 8无效，JDK8 将永生代移入到 metaspace -XX:MaxPermSize=512m 永生代最大值，JDK 8无效 -XX:MaxMetaspaceSize=512m 元空间初始化大小，JDK 8 -XX:newRatio=2 默认是2，新生代站1/3 -XX:Survivor=8 默认是8，两个 Survivor 共占用 2/10 -XX:NewSize 新生代初始化大小，一般和 -XX:MaxNewSize 设置同样大小，避免新生代内存伸缩 -XX:MaxNewSize 新生代最大值 -XX:InitialCodeCacheSize=128m “代码缓存”大小，“代码缓存”用来存储方法编译生成的本地代码 jvm 设置新生代大小jvm 设置新生代大小有很多组参数，大概分为三组： -XX:NewSize=1024m 和 -XX:MaxNewSize=1024m -Xmn1024m -XX:NewRatio=2 （假设Heap总共是3G） 在 JDK 4 之后，使用 -Xmn=1024m，相当于同时设置 -XX:NewSize=1024m 和 -XX:MaxNewSize=1024m，推荐使用 -Xmn 关于 GC 日志相关参数 参数 说明 -XX:+PrintGC 打印GC日志 -XX:+PrintGCDetails 打印GC详细日志，包括-XX:+PrintGC -XX:+PrintGCTimeStamps 打印GC时间戳 -XX:+PrintGCDateStamps 打印GC时间戳，以日期为准 -XX:+PrintHeapAtGC 在运行GC的前后打印堆信息 -XX:+PrintTenuringDistribution 新生代GC的时候，打印存活对象的年龄分布 -XX:HeapDumpPath=/opt/log/oomlogs 内存溢出时保存当时的内存快照 -+HeapDumpOnOutOfMemoryError 发生OOM时，保存dump内存快照 关于 GC 行为相关参数CMS 相关参数 参数 含义 -XX:+DisableExplicitGC 禁用显示调用，System.gc()将成为空调用 -XX:+UseConcMarkSweepGC 使用CMS收集器收集老年代，特点是低停顿，停顿少。吞吐量相对较低，适合短连接事务型系统 -XX:CMSInitiatingOccupancyFraction=80 在默认设置下，CMS收集器在老年代使用了68%的空间后就会被激活，可以适当调高，实际应用中老年代增长不会太快 G1 相关参数 参数 含义 -XX:G1HeapRegionSize=n 设置Region大小，并非最终值 -XX:MaxGCPauseMillis 设置G1收集过程目标时间，默认值200ms，不是硬性条件 -XX:G1NewSizePercent 新生代最小值，默认值5% -XX:G1MaxNewSizePercent 新生代最大值，默认值60% -XX:ParallelGCThreads STW期间，并行GC线程数 -XX:ConcGCThreads=n 并发标记阶段，并行执行的线程数 -XX:InitiatingHeapOccupancyPercent 设置触发标记周期的 Java 堆占用率阈值。默认值是45%。这里的java堆占比指的是non_young_capacity_bytes，包括old+humongous 参考https://eyesmore.iteye.com/blog/1530996https://stackoverflow.com/questions/7871870/what-is-the-difference-between-x-params-and-xx-params-in-jvm]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx实现原理]]></title>
    <url>%2Fnginx-implement.html</url>
    <content type="text"><![CDATA[简单理解 Nginxnginx 是静态 web 服务器，意思是 engine x。并发量高， Nginx 事件驱动模型事件驱动模型是 Nginx 服务器保障完整可用功能和具有良好性能的重要机制之一 事件驱动模型概述包括事件收集器、事件发送器和事件处理器。 事件收集器，专门负责收集所有事件。例如用户的鼠标点击事件和键盘输入事件。 事件发送器将收集到的事件分发到各个目标对象。目标对象就是事件处理器的位置。 事件处理器负责具体事件的响应，它往往要到实现阶段才能完全确定。 Windows 系统就是基于事件驱动模型设计的典型案例，一个窗口就是时间发送器的目标对象。 nginx 事件驱动模型“事件发送器”每传递一个请求，“目标对象”就将其放入到待处理事件列表，使用非阻塞 I/O 方式调用“事件处理器”来处理请求。 大多数网络服务器采用这种方式，逐渐形成了所谓的“事件驱动处理库”。 事件驱动处理库又叫多路 I/O 复用方法，常见的包括 select 模型、pull 模型 和 epoll 模型。 select 模型文件描述符有3类，分别是write、read和Exception。获取这三个 set 集合，有空间限制，最多1024个。轮询所有set集合，判断有事件发生的描述符 windows 和 linux 都有 poll 模型获取一个 链表的头头结点，轮询set集合，判断有事件发生的描述符 windows 没有 epoll 模型select、poll需要轮询，效率低。将描述符交给内核处理，如果就事件发生，就通知事件处理器 Nginx 服务器架构 大致分为主进程、工作进程、后端服务器和缓存。 主进程 配置文件解析 数据初始化 模块配置注册 信号处理 网络监听，建立、绑定和关闭 Socket 工作进程生成（fork）和管理 工作进程负责模块调用和请求处理 接受客户端请求 模块调用，将请求一次放入到各个模块过滤 IO 调用，请求转发后端服务器 结果返回，响应客户端请求 数据缓存，访问缓存索引，查询调用索引 响应主程序请求，重启、升级退出等 缓存索引重建和管理进程缓存索引重建 Cache loader，缓存管理 Cache manager 缓存索引重建进程，是在内存中建立缓存索引单元，缓存是存放在本地磁盘的 缓存管理进程负责判断索引单元是否过期 后端服务器将请求转发到后端服务器，实现反向代理和复杂均衡 缓存为实现高性能，采用缓存机制，将应答数据缓存到本地 参考《Nginx 高性能 Web 服务器详解》 Linux IO模式及 select、poll、epoll详解 - 人云思云 - SegmentFault 思否 https://martinguo.github.io/blog/2016/08/30/Nginx/]]></content>
      <categories>
        <category>javaWeb</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2FthreadLocal.html</url>
    <content type="text"><![CDATA[目标总结 ThreadLocal 实现原理，缺点，InheritableThreadLocal 原理，ThreadLocalRandom 中如何应用 ThreadLocal，Spring Bean 中如何 应用 ThreadLocal ThreadLocal提供线程本地变量，创建一个ThreadLocal需要及时销毁，不然会造成内存泄露。 先看下类图： 可知 Thread 类中有一个 threadLocals 和 inheritableThreadLocals 都是 ThreadLocalMap 类型的变量，而 ThreadLocalMap 是一个定制化的 Hashmap，默认每个线程中这个两个变量都为 null，只有当前线程第一次调用了 ThreadLocal 的 set 或者 get 方法时候才会进行创建。其 key 是 ThradLocal，value 是存放的数据。 每个线程本地数据不是存放在 ThreadLocal 里面，而是线程的 threadLocals 变量里。也就是说 ThreadLocal 类型的本地变量是存放到具体的线程内存空间的。 ThreadLocal 只是一个工具壳，他通过 set 方法将数据存放在线程的 threadLocals 变量里，通过 get 方法从线程的 thradLocals 里取数据。 注意点ThreadLocal 变量时线程封闭的，子线程不继承父线程的数据。且创建了ThreadLocal 变量用后需要及时销毁，否则会造成内存泄露。 InheritableThreadLocalInheritableThreadLocal 继承自 ThreadLocal，提供了一个特性，子线程可以继承父线程的 ThreadLocal 变量。 先看下代码： 12345678910111213public class InheritableThreadLocal extends ThreadLocal { protected T childValue(T parentValue) { return parentValue; } ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; } void createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); }} 可知 InheritableThreadLocal 就是讲 ThreadLocal 操作的 线程的 threadLocals 变量给成线程的 inheritableThreadLocals 变量，那么实现原理得从 Thread 来看。 在 Thread 类的 init 方法中有这样的代码： 123if (parent.inheritableThreadLocals != null) this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); 可知，在线程创建的时候，如果 inheritableThreadLocals 变量不为空会复制给子线程，这样就保证了 InheritableThreadLocal 类能够继承父类的 ThreadLocal 变量（似乎叫 InheritableThreadLocal 变量更合适） InheritableThreadLocal 使用场景比如存放用户登录信息的 threadlocal 变量，很有可能子线程中也需要使用用户登录信息，再比如一些中间件需要用统一的追踪 ID 把整个调用链路记录下来的情景。 ThreadLocalRandom 中的应用Random 在高并发下的缺陷先来看下 nextInt(int n) 的方法：1234567891011121314151617public int nextInt(int bound) { if (bound > 31); else { for (int u = r; u - (r = u % bound) + m < 0; u = next(31)) ; } return r;} 根据老种子获取新种子的方法：1234567891011protected int next(int bits) { long oldseed, nextseed; // 是原子变量 AtomicLong seed = this.seed; // 轮训 CAS 操作 do { oldseed = seed.get(); nextseed = (oldseed * multiplier + addend) & mask; } while (!seed.compareAndSet(oldseed, nextseed)); return (int)(nextseed >>> (48 - bits));} 根据上诉代码可知，生成一个随机数，需要先获取新种子，然后通过新种子来计算随机数。而获取新种子是存在并发问题的，因此 Random 的做法是将种子定义为原子变量，线程通过轮训 CAS 操作来得到新种子。这样虽然能保证线程安全，但是在高并发下会造成大量线程进行自旋重试和无畏的 CAS 操作。 ThreadLocalRandom 来了继承自 Random，先看下类图： ThreadLocalRandom 并没有维持一个原子变量种子，而是将每个线程的种子存放在线程的 threadLocalRandomSeed 变量中，ThreadLocalRandom 类像 ThreadLocal 类一样是一个工具类。值得注意的是 threadLocalRandomSeed 是 long 类型，因为是线程封闭的。 Spring Request Scope 作用域 Bean 中 ThreadLocal 的使用我们知道 Spring 可以在配置 Bean 的时候可以指定 scpoe 属性来指定该 Bean 的作用域，singleton、prototype、request、session 等。其中 request 作用域就是通过 ThreadLocal 来实现的。 一个 web 请求的简要时序图如下： 每次发起 web 请求在 tomcat 中的 context（具体应用）前且在 host 匹配后，都会在 requestInitialized 方法中设置 RequestContextHolder 属性，在请求结束 requestDestroy 方法中会销毁。 setRequestAttributes 方法会设置属性到 ThreadLocal 变量，默认是不可继承的，可以设置为可继承，这样就会将属性保存到 InheritableThreadLocal 变量中。也就是说默认情况下，子线程访问不到存放在 RequestContextHolder 中的属性。 总结本文通过循序渐进的方式，先讲解了 ThreadLocal 的简单使用，然后讲解了 ThreadLocal 的实现原理，并指出 ThreadLocal 不支持继承性；然后紧接着讲解了 InheritableThreadLocal 是如何补偿了 ThreadLocal 不支持继承的特性；然后讲解了 ThreadLocalRandom 是如何借鉴 ThreadLocal 的思想补充了 Random 的不足；最后简单的介绍了 Spring 框架中如何使用 ThreadLocal 实现了 Reqeust Scope 的 Bean。 补充ThreadLocalMap 采用线性探测法ThreadLocalMap 内部是通过 “线性探测法” 来解决hash冲突的，不同于 HashMap 是通过链表法解决 hash 冲突。 ThreadLocalMap 采用 ThreadLocal 的弱引用作为 key。 线性探测法 就是在当前位置线性往后探测如果有空的位置就set https://zhuanlan.zhihu.com/p/37004598 拉链法与线程探测法优缺点 拉链法不会产生堆积现象，平均查找长度较短。但相对于线性探测法较浪费空间 防止内存泄露的最后一道防线——弱引用如果 ThreadLocalMap 采用的是强引用，这样引用 ThreadLocal 的对象被回收了，由于 ThreadLocal 一直被 ThreadLocalMap 强引用着而不能被回收，从而导致 Entry 内存泄露。 如果是弱引用，就算你不显示的调用 remove 方法，在 gc 执行的时候，如果一个对象只被弱引用着，就会无脑回收这个对象。就不会产生内存泄露。 但是日常开发中，还是要用完即删除，调用 remove 方法，会将 ThreadLocal 从 ThreadLocalMap 移除。 补充——ThreadLocal会造成内存泄露按照前面所说，ThreadLocalMap 采用的是弱引用，这样ThreadLocal会被回收，但是会出现 null-key 的情况。如果线程存货周期较长，那么会存在这样的强引用关系 Thread–>ThreadLocalMap–>Entry–>Value，这条强引用链会导致Entry不会回收，Value也不会回收，但Entry中的Key却已经被回收的情况，造成内存泄漏。 ThreadLocal 的 get()、set()、remove() 方法调用的时候会清除掉线程 ThreadLocalMap 中所有Entry中Key为null的Value，并将整个 Entry 设置为null，利于下次内存回收 参考Java 并发编程之美：并发编程高级篇之一 https://zhuanlan.zhihu.com/p/37004598]]></content>
      <categories>
        <category>java进阶</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>threadlocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java常量池]]></title>
    <url>%2Fjava-constant-pool.html</url>
    <content type="text"><![CDATA[概述java 包括三种常量池，分别是 字符串常量池、Class 常量池（也叫常量池表）和运行时常量池。 字符串常量池（String Pool）String Pool 是 JVM 实例全局共享的，而 Runtime Constant Pool 是每个类都有一个。 JVM 用一个哈希表记录对常量池的引用。 String Pool 在 JDK1.7 之前是存放在方法区中的，JDK1.7 移入到堆中。可以测试下往List中无限放入String，看jdk各个版本的异常信息。jdk6是PermGen Space内存溢出，jdk7和8都是Java heap space内存溢出。 常量池表（Constant Pool Table）为了让 java 语言具有良好的跨平台性，java 团队提供了一种可以在所有平台上使用的中间代码——字节码（byte code），字节码需要在虚拟机上运行。像 Groovy、JRuby、Jython、Scala等，也会编译成字节码，也能够在 Java 虚拟机上运行。 java 文件会编译成 Class 文件，ClassClass 文件包含了 Java 虚拟机指令集和符号表以及其他辅助信息。Class文件中除了包含类的版本、字段、方法、接口等描述信息外，还有一项信息(constant pool table)，用于存放编译器生成的各种字面量(Literal)和符号引用(Symbolic References)。也就是说常量池表示属于 Class 字节码文件中的一类结构化数据，Class 文件内容如下 举个栗子。 一个 HelloWord.java 文件 12345public class HelloWord { public static void main(String[] args) { String s = "helloword"; }} 会编译成 HelloWord.class 文件，通过反编译命令 javap -v HelloWorld.class 可以查看其内容。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263Classfile /Users/zhouxinghang/workspace/study/target/classes/com/zxh/study/test/HelloWord.class Last modified 2019-3-13; size 465 bytes MD5 checksum 3a7da1e8436a92ff3dacb4f45d30e7d9 Compiled from "HelloWord.java"public class com.zxh.study.test.HelloWord minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#20 // java/lang/Object."":()V #2 = String #21 // helloword #3 = Class #22 // com/zxh/study/test/HelloWord #4 = Class #23 // java/lang/Object #5 = Utf8 #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 LocalVariableTable #10 = Utf8 this #11 = Utf8 Lcom/zxh/study/test/HelloWord; #12 = Utf8 main #13 = Utf8 ([Ljava/lang/String;)V #14 = Utf8 args #15 = Utf8 [Ljava/lang/String; #16 = Utf8 s #17 = Utf8 Ljava/lang/String; #18 = Utf8 SourceFile #19 = Utf8 HelloWord.java #20 = NameAndType #5:#6 // "":()V #21 = Utf8 helloword #22 = Utf8 com/zxh/study/test/HelloWord #23 = Utf8 java/lang/Object{ public com.zxh.study.test.HelloWord(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object."":()V 4: return LineNumberTable: line 7: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/zxh/study/test/HelloWord; public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=1, locals=2, args_size=1 0: ldc #2 // String helloword 2: astore_1 3: return LineNumberTable: line 9: 0 line 10: 3 LocalVariableTable: Start Length Slot Name Signature 0 4 0 args [Ljava/lang/String; 3 1 1 s Ljava/lang/String;} 字面量（literal） 在计算机科学中，字面量（literal）是用于表达源代码中一个固定值的表示法（notation）。几乎所有计算机编程语言都具有对基本值的字面量表示，诸如：整数、浮点数以及字符串；而有很多也对布尔类型和字符类型的值也支持字面量表示；还有一些甚至对枚举类型的元素以及像数组、记录和对象等复合类型的值也支持字面量表示法。 上述是计算机科学对字面量的解释，在 Java 中，字面量包括：1.文本字符串 2.八种基本类型的值 3.被声明为 final 的常量等。 字面量只可以右值出现。如 String s = "helloword"，s 为左值，helloword 为右值，helloword 为字面量。 符号引用（Symbolic References）符号引用是编译原理的概念，1是相对于直接引用来说的。在 Java中，符号引用包括：1.类和方法的全限定名 2.字段的名称和描述符 3.方法的名称和描述符。 常量池表的作用常量池表（Class 常量池）是 Class 文件的资源仓库，保存了各种常量。 在《深入理解Java虚拟机》中有这样的描述： Java代码在进行Javac编译的时候，并不像C和C++那样有“连接”这一步骤，而是在虚拟机加载Class文件的时候进行动态连接。也就是说，在Class文件中不会保存各个方法、字段的最终内存布局信息，因此这些字段、方法的符号引用不经过运行期转换的话无法得到真正的内存入口地址，也就无法直接被虚拟机使用。当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址之中。关于类的创建和动态连接的内容，在虚拟机类加载过程时再进行详细讲解。 运行时常量池（Runtime Constant Pool） JVM 运行时内存中方法区的一部分，所以也是全局共享的，是运行时的内容 运行时常量池相对于 Class 常量池一大特征就是其具有动态性，Java 规范并不要求常量只能在运行时才产生，也就是说运行时常量池中的内容并不全部来自 Class 常量池，Class 常量池并非运行时常量池的唯一数据输入口；在运行时可以通过代码生成常量并将其放入运行时常量池中 同方法区一样，当运行时常量池无法申请到新的内存时，将抛出 OutOfMemoryError 异常。 这部分数据绝大部分是随着 JVM 运行，从常量池表转化而来，每个 Class（不是 Java 对象） 都对应一个运行时常量池。（上面说绝大部分是因为：除了Class 中常量池内容，还可能包括动态生成并加入这里的内容） 为什么 Java 需要设计常量池，而 C 没有？在 C/C++ 中，编译器将多个编译器编译的文件链接成一个可执行文件或 dll 文件，在链接阶段，符号引用就解析为实际地址。而 java 中这种链接是在程序运行时动态进行的。 jvm 在栈帧(frame) 中进行操作数和方法的动态链接(link)，为了便于链接，jvm 使用常量池来保存跟踪当前类中引用的其他类及其成员变量和成员方法。 当一个 java class 被编译时，所有的变量和方法都装载到 Class 常量池作为一个符号引用。JVM 实现何时去解析符号引用，可以发生在类加载后的验证步骤称为静态解析，也可以发生在第一次使用的时候称为延迟解析。 参考https://blog.csdn.net/u010297957/article/details/50995869 https://blog.csdn.net/luanlouis/article/details/39960815 http://blog.jamesdbloom.com/JVMInternals.html]]></content>
      <categories>
        <category>java基础</category>
      </categories>
      <tags>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS相关]]></title>
    <url>%2FAQS.html</url>
    <content type="text"><![CDATA[AQS 简单介绍AbstractQueuedSynchronizer，抽象同步队列。是实现同步的基础组件，并发包中的锁都是基于 AQS 实现。 内部有一个 state 变量，用于表示一些状态信息，这个状态信息具体由实现类决定，比如一个 ReentrantLock 类这个 state 就表示获取锁的次数。 内部维持两个队列，Sync Queue 和 Condition Queue，Sync Queue 是一个双向 FIFO 链表，是锁的时候用到。而 Condition Queue 是条件队列，作为锁的等待条件时用到。 这个类使用到了模板方法设计模式：定义一个操作中算法的骨架，而将一些步骤的实现延迟到子类中。 AQSAQS 类简单介绍先看一下 AQS 的类图 AQS 是一个 FIFO 的双向队列，内部通过 tail 和 head 来记录队尾和队首，队列元素为 Node，状态信息为 state，通过内部类 ConditionObject 来结合锁实现线程同步 Node 节点：Note 的属性 thread 来存储进入 AQS 的线程（竞争锁失败进入等待队列）；Node 节点内部 SHARED 表示是获取共享资源被阻塞挂起后放入 AQS 队列的，EXCLUSIVE 表示获取独占资源被阻塞后挂起放入到 AQS 队列的；prev 记录当前节点的前驱节点，next 记录当前节点的后续节点。 waitStatus 表示当前线程等待状态，分别为 CANCELLED（线程被取消），SIGNAL（线程需要被唤醒），CONDITION（线程在条件队列里面等待），PROPAGATE（释放共享资源时候需要通知其他节点）， state 状态信息： AQS 中维持了一个单一的状态信息 state，可以通过 getState、setState 和 compareAndSetState 函数修改其值 ReentrantLock：当前线程获取锁的次数 ReentrantReadWriteLock：state 高16位表示读状态也就是获取读锁的线程数，低16位表示写状态也就是获取写锁的次数 Semaphore：当前可用信号个数 FutureTask：开始，运行，完成，取消 CountDownlatch 和 CyclicBarrie：计数器当前的值 ConditionObject 内部类： AQS 通过内部类 ConditionObject 来结合锁实现线程同步，ConditionObject 可以直接访问 AQS 内部变量（state 状态值和 Node 队列）。ConditionObject 是条件变量，每个条件变量对应一个条件队列（单向链表），线程调用条件变量的 await 方法后阻塞会放入到该队列，如类图，条件队列的头尾元素分别为 firstWaiter 和 lastWaiter。 AQS 实现同步原理AQS 通过操作 state 状态变量实现同步的操作。操作 state 分为共享模式和独占模式。 独占模式获取和释放锁方法为： 123void acquire(int arg) void acquireInterruptibly(int arg) boolean release(int arg) 共享模式获取和释放锁方法为： 123void acquireShared(int arg) void acquireSharedInterruptibly(int arg) boolean releaseShared(int arg) Interruptibly关键字的方法： 带 Interruptibly 关键字的方法会对中断进行相应，也就是在线程调用 acquireInterruptibly（或 acquireSharedInterruptibly） 方法获取资源时或获取资源失败被挂起的时候，其它线程中断了该线程，那么该线程会抛出 InterruptedException 异常而返回。 独占模式获取锁与共享模式获取锁区别： 独占模式获取锁是与具体线程绑定的，比如独占锁 ReentrantLock，如果线程获取到锁，会通过 CAS 操作将 state 从0变为1并且将当前锁的持有者设为该线程。当该线程再次获取锁时发现锁的持有者为自己，就会将 state +1，当另外的线程尝试获取锁，发现当前锁持有者不是自己，会被放入到 AQS 队列并挂起。 共享模式获取锁是与具体线程不相关的，多个线程请求请求资源时候是通过 CAS 方式竞争获取的，也就是说 CAS 操作只要成功就 OK。比如 Semaphore 信号量，当一个线程通过 acquire() 方法获取一个信号量时候，会首先看当前信号量个数是否满足需要，不满足则把当前线程放入阻塞队列，如果满足则通过自旋 CAS 获取信号量。 独占模式 acquire 源码分析12345public final void acquire(int arg) { if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); } 这是一个模板方法,获取锁 tryAcquire(arg) 的具体实现定义在子类中。 获取到锁 tryAcquire 就直接返回，否则调用 addWaiter 将当前节点添加到等待队列末尾。 1234567891011121314151617181920212223242526272829303132333435private Node addWaiter(Node mode) { // 将当前线程封装为 Node，设为独占模式 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure Node pred = tail; // 如果 tail 不为空，将 node 插入末尾 if (pred != null) { node.prev = pred; // 可能多个线程同时插入，用 CAS 操作 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 如果 tail 节点为空，或调用 CAS 操作将 当前节点设为 tail 节点失败 enq(node); return node;}private Node enq(final Node node) { for (;;) { Node t = tail; // 可能多个线程同时插入，重新判断是否为空 if (t == null) { // Must initialize if (compareAndSetHead(new Node())) tail = head; } else { node.prev = t; if (compareAndSetTail(t, node)) { t.next = node; return t; } } }} addWaiter 和 enq 方法是为了将当前线程 node 插入到队列末尾。插入成功后不会立即挂起当前线程，因为在 addWaiter 过程中前面的线程可能已经执行完。此时会调用自选操作 acquireQueued 让该线程尝试重新获取锁，如果获取锁成功就退出，否则继续。 123456789101112131415161718192021222324 final boolean acquireQueued(final Node node, int arg) { boolean failed = true; try { boolean interrupted = false; for (;;) { final Node p = node.predecessor(); // 如果其前驱节点为头结点，尝试获取锁，将该节点设为头结点，然后返回 if (p == head && tryAcquire(arg)) { // Called only by acquire methods setHead(node); p.next = null; // help GC failed = false; return interrupted; } // 如果获取锁失败，则判断是否需要挂起 if (shouldParkAfterFailedAcquire(p, node) && parkAndCheckInterrupt()) interrupted = true; } } finally { if (failed) cancelAcquire(node); }} 先尝试获取锁，失败再判断是否需要挂起，这个判断是通过它的前驱节点 waitStatus 确定的。 123456789101112131415161718192021222324252627private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) { int ws = pred.waitStatus; if (ws == Node.SIGNAL) /* * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws > 0) { /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do { node.prev = pred = pred.prev; } while (pred.waitStatus > 0); pred.next = node; } else { /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); } return false;} 如果前驱节点的 waitStatus 为： SINGAL，其前驱节点将要被唤醒，该节点可以安全的挂起，直接返回 true > 0，其前驱节点被取消，轮训将所有被取消的前驱节点都剔除，然后返回 false < 0，其前驱节点为 0 或 PROPAGATE，将前驱节点置为 SINGAL 表示自己将处于阻塞状态（下次判断时，会走 ws == Node.SIGNAL 的分支），然后返回 false。 返回 false，表示会重新执行 acquireQueued 方法，然后再重新检查前驱是不是头结点重新try一下什么的，也是之前描述的流程。 获取独占锁过程总结： AQS的模板方法acquire通过调用子类自定义实现的tryAcquire获取同步状态失败后->将线程构造成Node节点(addWaiter)->将Node节点添加到同步队列对尾(addWaiter)->节点以自旋的方法获取同步状态(acquirQueued)。在节点自旋获取同步状态时，只有其前驱节点是头节点的时候才会尝试获取同步状态，如果该节点的前驱不是头节点或者该节点的前驱节点是头节点单获取同步状态失败，则判断当前线程需要阻塞，如果需要阻塞则需要被唤醒过后才返回。 独占模式 release 源码分析AQS 的 release 释放同步状态和 acquire 获取同步状态一样，都是模板方法，tryRealease 具体操作都由子类实现，父类 AQS 只是提供一个算法骨架。 123456789public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null && h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 如果释放成功，会解锁头节点的后续节点。 1234567891011121314151617181920212223242526272829private void unparkSuccessor(Node node) { /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws < 0) compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; // 如果后续节点为空或是作废节点 if (s == null || s.waitStatus > 0) { s = null; // 从末尾开始找合适的节点 for (Node t = tail; t != null && t != node; t = t.prev) if (t.waitStatus MAX_COUNT) throw new Error("Maximum lock count exceeded"); // Reentrant acquire setState(c + acquires); return true; } // 读写锁都未被获取 if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) return false; setExclusiveOwnerThread(current); return true;} writerShouldBlock 方法对于非公平锁，是直接返回false，这样就会走 CAS 操作，与别的所有线程一起竞争，也就是后来的线程与先来的线程一起“插队”竞争。writerShouldBlock 方法对于公平锁，会调用 hasQueuedPredecessors 会判断是否有前驱节点，如果有则直接放回放弃进竞争，毕竟别人先来的要公平。 写锁的释放： 释放写锁会调用 release 方法，release 是 AQS 的模板方法，tryRelease 由子类实现，我们来看tryRelease。 1234567891011121314protected final boolean tryRelease(int releases) { // 判断是否是写锁拥有者 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 获取释放锁后的 可重入 值 int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; // 如果可重如值为0，就释放锁 if (free) setExclusiveOwnerThread(null); // 写锁只有一个线程，不需要 CAS 操作 setState(nextc); return free;}tryAcquireShared 读锁的获取和释放读锁通过 ReadLock 来实现，读锁是共享锁。 读锁的获取： 调用 AQS 的 acquireShared 方法，内部调用 ReentrantReadWriteLock 中的 Sync 重写的 tryAcquireShared 方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950protected final int tryAcquireShared(int unused) { /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ Thread current = Thread.currentThread(); int c = getState(); // 如果写锁被获取，且不是当前线程 if (exclusiveCount(c) != 0 && getExclusiveOwnerThread() != current) return -1; // 获取了读锁的线程数，别搞成是可重入数量 int r = sharedCount(c); // 尝试获取读锁，多个线程只有一个成功，不成功的会进入下面的 fullTryAcquireShared 方法 if (!readerShouldBlock() && r < MAX_COUNT && compareAndSetState(c, c + SHARED_UNIT)) { // 第一个获取读锁 if (r == 0) { firstReader = current; firstReadeHoldCount = 1; // 是第一个获取读锁的线程 } else if (firstReader == current) { firstReaderHoldCount++; } else { HoldCounter rh = cachedHoldCounter; // 将获取到读锁的当前线程和可重入数记录到 cachedHoldCounter 中 if (rh == null || rh.tid != getThreadId(current)) cachedHoldCounter = rh = readHolds.get(); // cachedHoldCounter 为当前线程，将其保存到 readHolds 中 else if (rh.count == 0) readHolds.set(rh); rh.count++; } return 1; } // 自旋 CAS 获取读锁 return fullTryAcquireShared(current);} readerShouldBlock 方法会判断是否需要阻塞，在公平锁和非公平锁有不同的实现。 在非公平锁下，如果同步等待队列中有获取写锁的线程在排队，则获取读锁的该线程会阻塞，否则直接尝试获取读锁。 1234567891011121314static final class NonfairSync extends Sync { final boolean readerShouldBlock() { return apparentlyFirstQueuedIsExclusive(); }}final boolean apparentlyFirstQueuedIsExclusive() { Node h, s; return (h = head) != null && // AQS 第一个 node 是虚拟节点 (s = h.next) != null && !s.isShared() && s.thread != null;} 在公平锁下，如果同步队列中有其他线程在排队，则获取读锁的该线程会阻塞，这里和写锁是一样的，先来后到~ 12345static final class FairSync extends Sync { final boolean readerShouldBlock() { return hasQueuedPredecessors(); }} 读锁的释放： 直接看 tryReleaseShared 方法 123456789101112131415161718192021222324252627282930313233protected final boolean tryReleaseShared(int unused) { Thread current = Thread.currentThread(); // 先 firstReader 再 cachedHoldCounter 最后 readHolds if (firstReader == current) { // assert firstReaderHoldCount > 0; if (firstReaderHoldCount == 1) firstReader = null; else firstReaderHoldCount--; } else { HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); int count = rh.count; // 为0 记得在 ThreadLocal 中 remove if (count]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>锁</tag>
        <tag>源码分析</tag>
        <tag>Lock</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的锁]]></title>
    <url>%2Fjava-lock.html</url>
    <content type="text"><![CDATA[公平锁和非公平锁公平锁好处是等待锁的线程不会饿死，但整体效率较低。非公平锁好处是整体效率高一些，但是有些线程可能需要等待很久才能获取到锁。因为非公平锁是可以抢占的。 两者内部都维持一个 AQS 等待队列（FIFO），放置等待等待获取锁的线程。如果释放锁的时候，没有新的线程来获取锁，这时候就会从 AQS 队列头取出线程让其获取到锁。这时候公平锁和非公平锁是一样的。如果释放锁的时候，刚好有新的线程来获取锁，非公平锁就会将锁分配给这个新的线程，这就是非公平锁的抢占式。因为非公平锁中新来的线程有一定几率不会被挂起，减少了整体线程挂起的几率，所以非公平锁性能高于公平锁。 公平锁可以使用new ReentrantLock(true)实现。 自旋锁java 的线程是映射到操作系统的，线程的阻塞和唤醒需要操作系统来完成，这就需要从用户态转换到核心态，增加了状态切换的耗时。许多应用的共享数据的锁定状态自会持续很短的时间，为了这点时间去挂起和恢复现场不值得。我们可以让请求锁的线程自旋等待，不放弃CPU时间，直到获取到锁。 自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK6中已经变为默认开启，并且引入了自适应的自旋锁。自适应意味着自旋的时间不在固定了，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。 自旋锁是通过 CAS 实现的，即不断重试 CAS 直到成功为止。自旋锁存在的问题如下： 占用过多 CPU 时间 死锁问题，在递归调用中，同一个线程获取到自旋锁，由再次申请获取 ABA 问题，java 中自旋锁一般是利用 CAS 操作实现 jdk 中 atomic 包下都是采用自旋锁原理 锁消除锁消除是指 JVM 在 JIT 编译时，通过扫描上下文，去除不可能存在共享资源竞争的锁。通过锁消除，可以减少无畏的请求锁时间。 锁消除的主要判断依据是来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而能被其他线程访问到，那就可以把他们当做栈上数据对待，认为他们是线程私有的，同步加锁自然就无需进行。 比如下面这个代码 public String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } JIT 回去除 append 方法的加锁 锁粗化一般情况下，都是推荐加锁范围越小越好。但是如果连续几行代码都是对同一个对象加锁解锁，甚至加锁操作出现循环体中。虚拟机遇到这样的情况，会将加锁范围扩大到整个操作序列的外部 比如下面的代码 StringBuffer sb = new StringBuffer(); public String concatString(String s1, String s2, String s3) { StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString(); } 因为 StringBuffer 定义在方法体外面，存在锁竞争，每个 append 都会加解锁，jvm 会将加锁范围扩大到 整个 append 操作序列的外部 可重入锁可重入锁也叫递归锁，同一线程可以多次获取同一个锁。可重入锁避免了死锁，synchronizez 和 ReentrantLock 都是可重入锁 类锁和对象锁 public class SynchronizedTest { public static synchronized void method1() {} public void method2() { synchronized(LockStrategy.class) {} } public synchronized void method3() {} } 其中 method1 和 method2 都是类锁，method3 是对象锁 偏向锁、轻量级锁和重量级锁在 jdk6 之前， synchronizez 一直是一个重量级锁，在 jdk6 中对 synchronized 做了很多优化，引入了偏向锁和轻量级锁。 对象头锁存在于 java 对象头中，如果对象是数组类型，则虚拟机用 3 个 Word（字宽）存储对象头，如果对象是非数组类型，则用 2 字宽存储对象头。在 32 位虚拟机中，一字宽等于四字节，即 32bit。 长度 内容 说明 32/64 bit Mark Word HashCode，分代年龄和锁标记位 32/64 bit Class Metadata Address 存储对象的类型指针 32/64 bit Array length 数组的长度（如果当前对象是数组） Class Metadata Address 用于存储对象的类型指针，该指针指向它的类元数据，JVM通过这个指针确定对象是哪个类的实例 Mark WordJava 对象头里的 Mark Word 里默认存储对象的 HashCode，分代年龄和锁标记位。32位 JVM 的 Mark Word 存储结果如下 其中 epoch 为偏向时间戳。 偏向锁偏向锁是为了消除无竞争情况下的同步原语，进一步提升程序性能。 偏向锁会偏向于第一个获取到他的线程，只要没有别的线程获取该锁，那么这第一个线程将永远不需要同步。 public synchronized void method() { // do ... } 如上述代码，线程A 第一个获取到这个锁，那么线程A后续执行 method，就不需要再进行获取锁的操作（只要中途没有别的线程来获取锁）。当有线程B来执行 method 时，偏向锁宣告结束，进入轻量级锁。 实现原理：当线程请求到锁对象后，将锁对象的状态标志位改为01，即偏向模式。然后使用CAS操作将线程的ID记录在锁对象的Mark Word中。以后该线程可以直接进入同步块，连CAS操作都不需要。但是，一旦有第二条线程需要竞争锁，那么偏向模式立即结束，进入轻量级锁的状态。 优点：偏向锁可以调高有同步但是没有竞争的程序性能，但是如果锁对象同时被多个线程竞争，那么偏向锁是多余的 偏向锁可以通过 JVM 参数来关闭：-XX:-UseBiasedLocking=false 轻量级锁使用 CAS 操作代替互斥同步，在线程请求锁时 实现原理：在线程请求锁时，判断锁对象的 Mark Word 是否是无锁状态（锁标志位为01，是否偏向为0），然后在线程的栈帧中创建一块 Lock Record 空间，并将锁对象的 Mark Word 复制到 Lock Record中，然后通过 CAS 操作将锁对象的 Mark Word 替换为指向 Lock Record 的指针，并将 Lock Record 的 owner 指针指向 锁对象的 Mark Word。如下图： 获取锁失败的处理：如果成功则表示获取锁成功，如果失败，首先会检查锁对象的 Mark Word 是否指向当前线程的栈帧。如果是表示获取锁成功，如果还不是表示获取锁失败。此时轻量级锁膨胀为重量级锁，当前线程会尝试用自旋获取锁，后面的线程会阻塞等待。 前提：轻量级锁比重量级锁性能高的前提是，在轻量级锁被占用期间，不会发生锁的竞争。一旦发生锁竞争，会膨胀为重量级锁，除了使用互斥量外还额外增加了 CAS 操作。 获取锁失败了，为什么要重复检查 Mark Word因为可能是可重入锁 三者区别 重量级锁是一种悲观锁，而轻量级锁和偏向锁是乐观锁 轻量级锁是在无锁竞争情况下，使用 CAS 操作来代替互斥量使用。而偏向锁是在无锁竞争情况下，完全取消同步（只有第一次获取锁的时候会使用 CAS 操作） 轻量级锁适用场景是线程交替进入同步块，如果同一时间多个线程竞争同一把锁就会膨胀为重量级锁 一个线程重复访问同步块，轻量级锁每次都要进行 CAS 操作。而偏向锁是为了避免在无锁竞争情况下，不必要的 CAS 操作。只有第一次获取锁的时候会使用 CAS 操作 synchronized 通过监视器锁来实现同步（monitorenter 和 monitorexit），而监视器锁有依赖于底层的互斥锁，进入互斥锁需要用户态与和心态的切换，所以synchronized是重量级锁 乐观锁和悲观锁悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 乐观锁：假定不会发生并发冲突，只在提交操作时检测是否违反数据完整性。（使用版本号或者时间戳来配合实现） 读写锁读写锁是数据库常见的锁，又叫 共享-排它锁，S锁和X锁 共享锁：如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排它锁。获准共享锁的事务只能读数据，不能修改数据。 排它锁：如果事务T对数据A加上排它锁后，则其他事务不能再对A加任何类型的锁。获得排它锁的事务即能读数据又能修改数据。 读锁不能直接升级为写锁，需要重新获取写锁。 Java当中的读写锁通过ReentrantReadWriteLock实现 互斥锁同一时刻最多只有一个线程持有锁，在JDK中synchronized和JUC的Lock就是互斥锁。 无锁有些方法不涉及到共享数据，就不会出现线程安全问题，一定线程安全的有： 无状态编程 ThreadLocal等线程封闭方案 volatile（volatile只能保证可见性和防止重排序，并不能保证线程安全） CAS 协程，单线程内维持多个任务的调度 分段锁ConcurrentHashMap，在 java8 之前，ConcurrentHashMap 采用的是 分段锁技术来减少锁粒度。java8 摈弃了分段锁，采用的是 CAS 操作 和 synchronized 锁。 闭锁闭锁是一种同步工具类，可以延迟线程的进度直到其到达终止状态。闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门一直是关闭的，并且没有任何线程能通过，当到达结束状态时，这扇门会打开允许所有的线程通过。当闭锁到达结束状态后，将不会再改变状态，因此这扇门将永远保持打开状态。闭锁可以用来确保某些活动指导其他活动都完成后才继续执行。CountDownLatch就是一种灵活的闭锁实现。 死锁多个线程因资源竞争而相互等待的现象。出现死锁必须满足4个条件： 互斥条件：一个资源一次只能被一个进程使用 请求与保持条件：一个进程因请求资源而阻塞等待，对已获取的资源保持不放 不剥夺条件：进程已获取的资源，不会被剥夺 循环等待条件：若干进程形成循环等待资源的关系。 活锁LiveLock是一种形式活跃性问题，该问题尽管不会阻塞线程，但也不能继续执行，因为线程将不断重复执行相同的操作，而且总会失败。活锁通常发送在处理事务消息的应用程序中：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头：如果不能成功地处理某个消息，那么消息处理机制将回滚整个事务，并将它重新放到队列的开头。如果消息处理器在处理某种特定类型的消息时存在错误并导致它失败，那么每当这个消息从队列中取出并传递到存在错误的处理器时，都会发生事务回滚。由于这条消息又被放回到队列开头，因此处理器将被反复调用，并返回相同的结果。 参考https://www.infoq.cn/article/java-se-16-synchronized https://www.zhihu.com/question/55075763 https://hiddenpps.blog.csdn.net/article/details/51204385 https://my.oschina.net/dabiaoge/blog/1613180]]></content>
      <categories>
        <category>java进阶</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>锁</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo deploy 指定 git 账户]]></title>
    <url>%2Fhexodeploy-edit-gitaccount.html</url>
    <content type="text"><![CDATA[问题hexo deploy默认使用全局的git user.name user.email，通过设置自定义 git 用户 操作在 hexo 全局 _config.yml 中添加配置 12345678deploy: type: git repo: branch: [branch] message: [message] name: [git user] email: [git email] extend_dirs: [extend directory] 然后需要删除 .deploy_git 目录，重新 hexo deploy 生成即可 参考https://github.com/hexojs/hexo/issues/2125]]></content>
      <categories>
        <category>计算机操作</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java内存模型]]></title>
    <url>%2Fjava-memory-model.html</url>
    <content type="text"><![CDATA[基础现代计算机物理内存模型 访问局部性（英语：Locality of reference） 访问局部性分为两种基本形式，一种是时间局部性，另一种是空间局部性。时间局部性指的是，程序在运行时，最近刚刚被引用过的一个内存位置容易再次被引用，比如在调取一个函数的时候，前不久才调取过的本地参数容易再度被调取使用。空间局部性指的是，最近引用过的内存位置以及其周边的内存位置容易再次被使用。空间局部性比较常见于循环中，比如在一个数列中，如果第3个元素在上一个循环中使用，则本次循环中极有可能会使用第4个元素。 指令重排序指令重排序是为了提高程序性能做得优化，比如多次写操作，每次都要会写内存，可以在线程的 working memory 操作完成后，一起回写内存。 指令重排序包括： 编译器优化重排序 指令级并行重排序 内存系统的重排序 as-if-serial无论如何重排序,程序执行的结果都应该与代码顺序执行的结果一致(Java编译器,运行时和处理器都会保证java在单线程下遵循as-if-serial语义). 线程的 working memory是 cache 和寄存器的抽象，解释源于《Concurrent Programming in Java: Design Principles and Patterns, Second Edition》，而不单单是内存的某个部分 Java 内存模型（Java Memory Model）Java内存模型(Java Memory Model)描述了Java程序中各种变量(线程共享变量)的访问规则,以及在JVM中将变量存储到内存和从内存中读取出变量这样的底层细节. happens-before 原则规定了 java 指令操作的偏序关系。是 JMM 制定的一些偏序关系，用于保证内存的可见性。 8大 happens-before 原则： 单线程happen-before原则：在同一个线程中，书写在前面的操作happen-before后面的操作。 锁的happen-before原则：同一个锁的unlock操作happen-before此锁的lock操作。 volatile的happen-before原则：对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包括写操作了)。 happen-before的传递性原则：如果A操作 happen-before B操作，B操作happen-before C操作，那么A操作happen-before C操作。 线程启动的happen-before原则：同一个线程的start方法happen-before此线程的其它方法。 线程中断的happen-before原则：对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的代码。 线程终结的happen-before原则：线程中的所有操作都happen-before线程的终止检测。 对象创建的happen-before原则：一个对象的初始化完成先于他的finalize方法调用。 内存可见性共享变量实现可见性原理线程1对共享变量的修改对线程2可见，需要2个步骤： 将工作内存1中修改的共享变量刷新到主内存 将主内存最新的共享变量更新到工作内存2 synchronizedJMM 关于synchronized 的两条规定： 线程解锁前，刷新共享变量到主存 线程加锁前，获取主存中共享变量最新值到工作内存 volatile有内存栅栏（或内存屏障）和防止指令重排序 JMM 中，在 volatile 变量写操作后加入 store 栅栏（(强制将变量值刷新到主内存中去)），在读操作前加入 load 栅栏（强制从主内存中读取变量的值） 参考https://www.jianshu.com/p/1508eedba54dhttps://www.jianshu.com/p/47f999a7c280http://ifeve.com/easy-happens-before/]]></content>
      <categories>
        <category>java进阶</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jvm</tag>
        <tag>jmm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伪共享]]></title>
    <url>%2Ffalse-sharing.html</url>
    <content type="text"><![CDATA[伪共享在 cpu 和 内存之间有高速缓存区（cache）,cache 一般集成在 cpu 内部，也叫做 cpu Cache。如下图是一个二级缓存示意图。 cache 内部是按照行来存储的，每行称为一个 cache 行，大小为2的n次幂，一个 cache 行 可能会存有多个变量数据 当多个线程同时修改一个 cache 行里面的多个变量时候，由于同时只能有一个线程操作缓存行，所以相比每个变量放到一个缓存行性能会有所下降，这就是伪共享。 当单个线程顺序访问同一个 cache 行的多个变量，利用程序运行局部性原理会加快程序运行。当多个程序同时访问同一个 cache 行的多个变量，会发生竞争，速度会慢]]></content>
      <categories>
        <category>java进阶</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fhello-world.html</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
